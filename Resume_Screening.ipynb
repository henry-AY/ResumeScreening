{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0abe05b-bd54-464e-ad8a-865291d488b1",
   "metadata": {},
   "source": [
    "# Resume Screening - Applicant Tracking System (ATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b17355-a12e-43dd-b11c-d4df8a817d40",
   "metadata": {},
   "source": [
    "Henry Yost, Riya Ashok, Angelina Jordan, Gokul Giridharan, and Refugio Zepeda Jr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4f577-4a57-418f-b805-7dfb7d5687f3",
   "metadata": {},
   "source": [
    "## Project Outline\n",
    "> Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10354909-d23e-4a6f-b296-f6231dc85791",
   "metadata": {},
   "source": [
    "## Dataset Exploration & Variables in the Dataset\n",
    "> Answer more in depth\n",
    "\n",
    "Given a dataset of resumes, can we assess if someone is qualified for the job position?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d9d3e-9ae4-43fe-b7e1-d6f101a2887e",
   "metadata": {},
   "source": [
    "### Plan\n",
    "\n",
    "1. Use BERT to classify the categories into 'buckets'\n",
    "2. Save each bucket as a new CSV file\n",
    "3. For the CSV file most closely related, find a very specific Job Description (i.e., Software Engineer @ Apple)\n",
    "4. Preprocess resumes (lowercasing, removing symbols, indents, etc)\n",
    "5. Use RegEx and hard criteria to filter resumes (Phase 1)\n",
    "6. Pick an IDEAL resume for the position (let's say the person is leaving, and use their resume as the ideal one to fill in the position)\n",
    "7. TF-IDF on applicants' resume and ideal --> Cosine similarity, Rank in order\n",
    "8. Human looks through the top 20 resumes and marks as qualified or not\n",
    "9. Use resume BERT embeddings for logistical regression\n",
    "10. Naive Bayes with TF-IDF?\n",
    "11. Lastly, combine via Soft voting, rank fusion or stacking (not sure which one would work best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a82b003-5049-40fb-b7c7-21a4edfad57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Importing\n",
    "import pandas as pd\n",
    "import re #RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038667e1-0325-4fbc-9d40-48fbe7669fa2",
   "metadata": {},
   "source": [
    "## 1. Importing Dataset & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b0ca81-d0ef-4494-9811-3a59ce1146b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv(\"Resume.csv\")\n",
    "df_orig = df_orig.drop(\"Resume_html\", axis=1) # Drop HTML, because we do not need it\n",
    "\n",
    "# All possible categories: HR, Designer, Information-Technology, Teacher, Advocate, Business-Development, \n",
    "# Healthcare, Fitness, Agriculture, BPO, Sales, Consultant, Digital-Media, Automobile, Chef, \n",
    "# Finance, Apparel, Engineering, Accountant, Construction, Public Relations, Banking, Arts, Aviation\n",
    "\n",
    "# Separate into approx 5 meaningful buckets\n",
    "df_tech = df_orig[df_orig['Category'].isin(['INFORMATION-TECHNOLOGY', 'ENGINEERING', 'DIGITAL-MEDIA', 'HR'])]\n",
    "df_tech = df_tech.copy()\n",
    "df_health_well = df_orig[df_orig['Category'].isin(['HEALTHCARE', 'FITNESS'])]\n",
    "df_bus_fin = df_orig[df_orig['Category'].isin(['BUSINESS-DEVELOPMENT', 'SALES', 'CONSULTANT', 'FINANCE', 'ACCOUNTANT', 'BANKING'])]\n",
    "df_creative_public = df_orig[df_orig['Category'].isin(['ARTS', 'DESIGNER', 'PUBLIC-RELATIONS', 'TEACHER', 'ADVOCATE', 'CHEF', 'APPAREL'])]\n",
    "df_indust = df_orig[df_orig['Category'].isin(['AGRICULTURE', 'AUTOMOBILE', 'CONSTRUCTION', 'AVIATION', 'BPO', 'CHEF', 'APPAREL'])]\n",
    "\n",
    "# Write each bucket to a CSV\n",
    "df_tech.to_csv(\"tech.csv\")\n",
    "df_health_well.to_csv(\"health_wellness.csv\")\n",
    "df_bus_fin.to_csv(\"business_finance.csv\")\n",
    "df_creative_public.to_csv(\"creative_public.csv\")\n",
    "df_indust.to_csv(\"industrial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "841f4a43-fdd6-4897-b068-421de45fa5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Category</th>\n",
       "      <th>Cleaned_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>HR</td>\n",
       "      <td>hr administrator marketing associate hr admini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>HR</td>\n",
       "      <td>hr specialist, us hr operations summary versat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>HR</td>\n",
       "      <td>hr director summary over 20 years experience i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>HR</td>\n",
       "      <td>hr specialist summary dedicated, driven, and d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>HR</td>\n",
       "      <td>hr manager skill highlights hr skills hr depar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str Category  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...       HR   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...       HR   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...       HR   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...       HR   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...       HR   \n",
       "\n",
       "                                         Cleaned_str  \n",
       "0  hr administrator marketing associate hr admini...  \n",
       "1  hr specialist, us hr operations summary versat...  \n",
       "2  hr director summary over 20 years experience i...  \n",
       "3  hr specialist summary dedicated, driven, and d...  \n",
       "4  hr manager skill highlights hr skills hr depar...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using RegEx to clean the Resume strings\n",
    "def clean_resume(text):\n",
    "    text = text.lower() # Make everything lowercase.\n",
    "    text = re.sub(r'\\s+', ' ', text) # replaces whitespace characters with a single space.\n",
    "    text = re.sub(r'\\/+', ' ', text) # replaces / characters with a single space (some resumes use backslashes)\n",
    "    text = re.sub(r'[^a-z0-9\\s\\.\\,\\-]', '', text) # keeps letters, numbers, whitespace, periods, and dashes.\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # replaces leading and trailing whitespace characters.\n",
    "    return text\n",
    "\n",
    "df_tech.loc[:, \"Cleaned_str\"] = df_tech[\"Resume_str\"].apply(clean_resume)\n",
    "\n",
    "# Also, there are no NaN values, so we don't need to drop any rows.\n",
    "\n",
    "df_tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cafe4971-db86-4eec-ba98-21e8f74bfcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score (0 to 1): 0.2636\n",
      "Similarity percentage: 26.36%\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained SBERT model (https://sbert.net/)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "first_resume = df_tech.iloc[0][\"Cleaned_str\"]\n",
    "tesla_job_desc = (\n",
    "    \"Develop, enhance and debug new and existing real-time software in C/C++ in embedded RTOS environments. \"\n",
    "    \"Work with HW and system teams on building testing infrastructure. Help design and bring up state of the art HIL/SIL validation infrastructure. \"\n",
    "    \"Help implement software tests for HIL/SIL infrastructure. Assist in tool development for testing and system integration. \"\n",
    "    \"Own implementation of software/firmware features end to end. What You'll Bring \"\n",
    "    \"Pursuing a Degree in Computer Science, Electrical Engineering, Physics or related field. \"\n",
    "    \"Desired to have strong understanding of Python debug simple circuits. \"\n",
    "    \"Desired to have good electrical and electronics fundamentals to be able to understand schematics and desired to have test driven development mindset. \"\n",
    "    \"Remain engaged, proactive and positive while solving very challenging problems. \"\n",
    "    \"Own assignments and take full accountability for overall team success. \"\n",
    "    \"Capable of delivering top quality C/ C++ code for embedded systems.\"\n",
    ")\n",
    "\n",
    "embed_resume = model.encode(first_resume)\n",
    "embed_jobdesc = model.encode(tesla_job_desc)\n",
    "\n",
    "similarity = cosine_similarity([embed_resume], [embed_jobdesc])[0][0]\n",
    "\n",
    "print(f\"Similarity score (0 to 1): {similarity:.4f}\")\n",
    "print(f\"Similarity percentage: {similarity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802ee9d-3de4-451c-b0a5-f720d7406b39",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd3c885a-85b9-4232-a516-e82dd43e924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /opt/anaconda3/lib/python3.12/site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (from wordcloud) (10.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from wordcloud) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->wordcloud) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->wordcloud) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->wordcloud) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[0;32m----> 5\u001b[0m cat_count \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      6\u001b[0m cat_count\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResume Count per Category\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "cat_count = df['Category'].value_counts()\n",
    "cat_count.plot(kind='bar')\n",
    "\n",
    "plt.title(\"Resume Count per Category\")\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933a9e4-8bc3-4045-a022-347b5ac4d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Category')['Resume_str'].apply(lambda texts: ' '.join(texts))\n",
    "\n",
    "for category, texts in grouped.items(): \n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        max_words=100\n",
    "    ).generate(texts)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f\"Word Cloud for Category: {category}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00377050-7f17-4ba3-8193-2c19cd61d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resume_length'] = df['Resume_str'].str.count(' ').add(1)\n",
    "average_length = df.groupby('Category')['resume_length'].mean()\n",
    "\n",
    "average_length.plot(kind='bar')\n",
    "plt.title(\"Avg Resume Length per Category\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Average Resume Length\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da1c85-bb1b-4b6b-a68a-bff0679aeb67",
   "metadata": {},
   "source": [
    "# Tesla Software and Energy Engineer\n",
    "## 1. First Resume Cleaning Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1905c5-74d5-47b1-8980-6a5476c26c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_job_desc = (\n",
    "    \"Develop, enhance and debug new and existing real-time software in C/C++ in embedded RTOS environments. \"\n",
    "    \"Work with HW and system teams on building testing infrastructure. Help design and bring up state of the art HIL/SIL validation infrastructure. \"\n",
    "    \"Help implement software tests for HIL/SIL infrastructure. Assist in tool development for testing and system integration. \"\n",
    "    \"Own implementation of software/firmware features end to end. What You'll Bring \"\n",
    "    \"Pursuing a Degree in Computer Science, Electrical Engineering, Physics or related field. \"\n",
    "    \"Desired to have strong understanding of Python debug simple circuits. \"\n",
    "    \"Desired to have good electrical and electronics fundamentals to be able to understand schematics and desired to have test driven development mindset. \"\n",
    "    \"Remain engaged, proactive and positive while solving very challenging problems. \"\n",
    "    \"Own assignments and take full accountability for overall team success. \"\n",
    "    \"Capable of delivering top quality C/ C++ code for embedded systems.\"\n",
    ")\n",
    "\n",
    "# Phase 1 filtering based on tesla_job_desc using ReGeX\n",
    "\n",
    "# 1. Parse and normalize resumes & job descriptions\n",
    "# 2. Extract requirements from job descriptions\n",
    "# 3. Define filter criteria & apply filters to resumes\n",
    "# 4. Potentially use BERT for semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2acf5-b924-4c8b-af87-207463929724",
   "metadata": {},
   "source": [
    "## 2. Second Resume Cleaning Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569dcab-c531-43d3-8a36-9d90d10f5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF-IDF and cosine similarity to rank the resumes based on the ideal resume "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f517a-0624-4986-a4b9-ba8179cde4dc",
   "metadata": {},
   "source": [
    "## 3. Third Resume Cleaning Cycle & SVM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b6f7d-20b7-4ce3-94ca-023702585444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM on synthetic lables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
